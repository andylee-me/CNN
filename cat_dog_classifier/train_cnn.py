import os
import json
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras import regularizers
from tensorflow.keras.mixed_precision import experimental as mixed_precision
from tensorflow.keras.applications.imagenet_utils import preprocess_input

# -----------------------
# ğŸ”§ åŸºæœ¬åƒæ•¸
# -----------------------
img_size = (224, 224)
batch_size = 32
train_dir = "file/kaggle_cats_vs_dogs_f/train"
val_dir = "file/kaggle_cats_vs_dogs_f/val"
model_dir = "model"
os.makedirs(model_dir, exist_ok=True)

# å¯é¸ï¼šé–‹å•Ÿæ··åˆç²¾åº¦ï¼ˆè‹¥ä½ çš„ GPU æ”¯æ´ï¼Œèƒ½åŠ é€Ÿä¸”çœé¡¯å­˜ï¼‰
try:
    policy = mixed_precision.Policy('mixed_float16')
    mixed_precision.set_policy(policy)
    print("âš¡ Using mixed precision (mixed_float16).")
except Exception as e:
    print("â„¹ï¸ Mixed precision not enabled:", e)

# -----------------------
# ğŸ” å‰è™•ç†èˆ‡è³‡æ–™å¢å¼·
#   - èˆ‡ PyTorch ç‰ˆæœ¬å°é½Šï¼šImageNet mean/stdï¼ˆmode='torch'ï¼‰
#   - ä¸å†ä½¿ç”¨ rescale=1./255
# -----------------------
train_datagen = ImageDataGenerator(
    preprocessing_function=lambda x: preprocess_input(x, mode="torch"),
    rotation_range=8,
    width_shift_range=0.03,
    height_shift_range=0.03,
    zoom_range=0.08,
    horizontal_flip=True,
    fill_mode='reflect'
)

val_datagen = ImageDataGenerator(
    preprocessing_function=lambda x: preprocess_input(x, mode="torch")
)

train_gen = train_datagen.flow_from_directory(
    train_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=True
)

val_gen = val_datagen.flow_from_directory(
    val_dir,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)

# å„²å­˜ class_indices ä¾› predict.py ä½¿ç”¨
with open(os.path.join(model_dir, "class_indices.json"), "w") as f:
    json.dump(train_gen.class_indices, f, indent=2, ensure_ascii=False)
print("ğŸ—‚ï¸ Saved class_indices.json:", train_gen.class_indices)

# -----------------------
# ğŸ§± æ¨¡å‹ï¼ˆåŠ æ·± + GAP + è¼•åº¦æ­£å‰‡ï¼‰
# -----------------------
l2 = regularizers.l2(1e-4)

model = Sequential([
    # Block 1
    Conv2D(32, (3,3), padding='same', activation='relu', kernel_regularizer=l2, input_shape=(img_size[0], img_size[1], 3)),
    BatchNormalization(),
    Conv2D(32, (3,3), padding='same', activation='relu', kernel_regularizer=l2),
    BatchNormalization(),
    MaxPooling2D(2,2),

    # Block 2
    Conv2D(64, (3,3), padding='same', activation='relu', kernel_regularizer=l2),
    BatchNormalization(),
    Conv2D(64, (3,3), padding='same', activation='relu', kernel_regularizer=l2),
    BatchNormalization(),
    MaxPooling2D(2,2),

    # Block 3
    Conv2D(128, (3,3), padding='same', activation='relu', kernel_regularizer=l2),
    BatchNormalization(),
    Conv2D(128, (3,3), padding='same', activation='relu', kernel_regularizer=l2),
    BatchNormalization(),
    MaxPooling2D(2,2),

    # Block 4ï¼ˆç¨å¾®å†æ·±ä¸€å±¤ï¼‰
    Conv2D(256, (3,3), padding='same', activation='relu', kernel_regularizer=l2),
    BatchNormalization(),
    MaxPooling2D(2,2),

    # Head
    GlobalAveragePooling2D(),
    Dense(256, activation='relu'),
    Dropout(0.3),
    Dense(1, activation='sigmoid')  # äºŒåˆ†é¡
])

# è‹¥å•Ÿç”¨ mixed precisionï¼Œæœ€å¾Œä¸€å±¤ä»¥ float32 è¨ˆç®—ï¼ˆKeras æœƒè‡ªå‹•è™•ç†å¤§éƒ¨åˆ†æƒ…æ³ï¼‰
# ä½†æœ‰æ™‚éœ€è¦æŒ‡å®š loss_scale æˆ–ç¢ºä¿è¼¸å‡º dtypeï¼Œé€™è£¡è®“ Keras è‡ªå‹•è™•ç†

model.compile(
    optimizer=Adam(learning_rate=1e-3),
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.summary()

# -----------------------
# â±ï¸ Callbacksï¼šå­¸ç¿’ç‡æ’ç¨‹ + æ—©åœ + æœ€ä½³æ¬Šé‡ä¿å­˜
# -----------------------
callbacks = [
    ReduceLROnPlateau(
        monitor='val_loss', factor=0.1, patience=5, verbose=1, min_lr=1e-6
    ),
    EarlyStopping(
        monitor='val_loss', patience=15, restore_best_weights=True, verbose=1
    ),
    ModelCheckpoint(
        filepath=os.path.join(model_dir, "catdog_model.h5"),
        monitor='val_accuracy',
        verbose=1,
        save_best_only=True
    )
]

# -----------------------
# ğŸš€ è¨“ç·´
# å»ºè­° 100â€“150 epochsï¼›æœ‰ LR æ’ç¨‹ + æ—©åœï¼Œå¯¦éš›ä¸æœƒè·‘æ»¿
# -----------------------
history = model.fit(
    train_gen,
    epochs=150,
    validation_data=val_gen,
    callbacks=callbacks,
    workers=4,
    use_multiprocessing=True
)

# å¦å­˜ä¸€ä»½æœ€çµ‚æ¬Šé‡ï¼ˆä¸ä¸€å®šæ˜¯æœ€ä½³ï¼‰
model.save(os.path.join(model_dir, "catdog_model_final.h5"))
print("âœ… Saved:", os.path.join(model_dir, "catdog_model_final.h5"))
