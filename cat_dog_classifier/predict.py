import os
import shutil
import json
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.imagenet_utils import preprocess_input

# 1ï¸âƒ£ æ¨¡å‹èˆ‡å°æ‡‰æª”æ¡ˆ
model_path = "model/catdog_model.h5"  # è¨“ç·´æ™‚å­˜åœ¨é€™è£¡
class_idx_path = "model/class_indices.json"

assert os.path.exists(model_path), f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹ {model_path}"
print(f"âœ… è¼‰å…¥æ¨¡å‹: {model_path}")
model = load_model(model_path)

if os.path.exists(class_idx_path):
    with open(class_idx_path, "r") as f:
        class_indices = json.load(f)
    print("ğŸ—‚ï¸ è¼‰å…¥ class_indices:", class_indices)
else:
    print("âš ï¸ æ‰¾ä¸åˆ° class_indices.jsonï¼Œå°‡ä¾è³‡æ–™å¤¾é †åºæ¨æ¸¬é¡åˆ¥ã€‚")

# 2ï¸âƒ£ è³‡æ–™å¤¾
train_dir = "file/kaggle_cats_vs_dogs_f/train"
val_dir = "file/kaggle_cats_vs_dogs_f/val"
img_size = (224, 224)  # èˆ‡è¨“ç·´å°é½Š

# 3ï¸âƒ£ å‰è™•ç†ï¼ˆèˆ‡è¨“ç·´å®Œå…¨ä¸€è‡´ï¼‰
datagen = ImageDataGenerator(
    preprocessing_function=lambda x: preprocess_input(x, mode="torch")
)
datasets = {"train": train_dir, "val": val_dir}

# 4ï¸âƒ£ æ¯æ¬¡å…ˆåˆªæ‰èˆŠçš„ misclassified
misclassified_dir = "misclassified"
if os.path.exists(misclassified_dir):
    shutil.rmtree(misclassified_dir)
os.makedirs(misclassified_dir, exist_ok=True)

def ensure_subdirs(base_path):
    """ç¢ºä¿ cat/dog å­è³‡æ–™å¤¾å­˜åœ¨"""
    for cls in ["cat", "dog"]:
        os.makedirs(os.path.join(base_path, cls), exist_ok=True)

def evaluate_and_save(dataset_name, dataset_path):
    print(f"\nğŸš€ é–‹å§‹æª¢æŸ¥ {dataset_name} è³‡æ–™é›†...")

    gen = datagen.flow_from_directory(
        dataset_path,
        target_size=img_size,
        batch_size=1,
        class_mode='binary',
        shuffle=False
    )

    total_images = len(gen.filepaths)
    print(f"â¡ å…±æ‰¾åˆ° {total_images} å¼µåœ–ç‰‡")

    pred_probs = model.predict(gen, verbose=1)
    pred_labels = (pred_probs > 0.5).astype(int).flatten()
    true_labels = gen.classes
    file_paths = gen.filepaths

    # label->name å°ç…§ï¼ˆè‹¥æœ‰ class_indices.json å°±ç”¨å®ƒï¼Œå¦å‰‡å¾ generator.classes å°æ‡‰ï¼‰
    if os.path.exists(class_idx_path):
        # class_indices æ˜¯ {class_name: index}
        idx_to_name = {v: k for k, v in class_indices.items()}
    else:
        # ä»¥ gen.class_indices æ¨å›
        idx_to_name = {v: k for k, v in gen.class_indices.items()}

    # å»ºç«‹ dataset å°æ‡‰è³‡æ–™å¤¾
    dataset_mis_dir = os.path.join(misclassified_dir, dataset_name)
    os.makedirs(dataset_mis_dir, exist_ok=True)
    ensure_subdirs(dataset_mis_dir)

    misclassified_count = 0
    debug_samples = 0

    for idx, (true_label, pred_label) in enumerate(zip(true_labels, pred_labels)):
        if true_label != pred_label:
            src_path = file_paths[idx]
            filename = os.path.basename(src_path)

            if not os.path.exists(src_path):
                print(f"âš ï¸ æ‰¾ä¸åˆ°åŸå§‹æª”æ¡ˆ: {src_path}")
                continue

            # å°‡åœ–ç‰‡ä¾ã€ŒçœŸå¯¦é¡åˆ¥ã€åˆ†åˆ°å°æ‡‰è³‡æ–™å¤¾
            true_name = idx_to_name.get(true_label, str(true_label))
            dst_cls = true_name  # "cat" æˆ– "dog"
            dst_path = os.path.join(dataset_mis_dir, dst_cls, f"wrong_pred_{filename}")
            shutil.copy(src_path, dst_path)
            misclassified_count += 1

            if debug_samples < 5:
                print(f"âŒ Misclassified -> {src_path} â†’ {dst_path}")
                debug_samples += 1

    acc = (1 - misclassified_count / total_images) * 100 if total_images > 0 else 0.0
    print(f"âœ… {dataset_name} é›†: å…± {total_images} å¼µ, éŒ¯èª¤ {misclassified_count}, æº–ç¢ºç‡ {acc:.2f}%")

    # å¦‚æœå®Œå…¨æ²’æœ‰éŒ¯èª¤ï¼Œè‡³å°‘æ”¾å€‹ README.txt ä»¥å… zip ç©ºè³‡æ–™å¤¾
    if misclassified_count == 0:
        with open(os.path.join(dataset_mis_dir, "README.txt"), "w") as f:
            f.write("This dataset has no misclassified images ğŸ‰")

# âœ… è·‘ train + val
for name, path in datasets.items():
    evaluate_and_save(name, path)

# âœ… æœ€å¾Œå°å‡ºå®Œæ•´ç›®éŒ„æ¨¹
print("\nğŸ“‚ æœ€çµ‚ misclassified è³‡æ–™å¤¾çµæ§‹ï¼š")
for root, dirs, files in os.walk(misclassified_dir):
    level = root.replace(misclassified_dir, "").count(os.sep)
    indent = " " * 2 * level
    print(f"{indent}ğŸ“ {os.path.basename(root)}/")
    for f in files:
        print(f"{indent}  â”œâ”€â”€ {f}")
