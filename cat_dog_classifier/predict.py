import os
import shutil
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# 1ï¸âƒ£ æ¨¡å‹è·¯å¾‘
model_path = "model/catdog_model.h5"
if not os.path.exists(model_path):
    raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æª”æ¡ˆ {model_path}ï¼Œè«‹å…ˆè¨“ç·´æ¨¡å‹ï¼")
model = load_model(model_path)

# 2ï¸âƒ£ å®šç¾©è³‡æ–™å¤¾
train_dir = "file/kaggle_cats_vs_dogs_f/train"
val_dir = "file/kaggle_cats_vs_dogs_f/val"
img_size = (128, 128)

# 3ï¸âƒ£ é è™•ç†å™¨
datagen = ImageDataGenerator(rescale=1./255)

# 4ï¸âƒ£ è¦è™•ç†çš„è³‡æ–™é›†
datasets = {
    "train": train_dir,
    "val": val_dir
}

# 5ï¸âƒ£ å»ºç«‹ misclassified è³‡æ–™å¤¾ï¼ˆå…ˆåˆªé™¤èˆŠçš„ï¼Œç¢ºä¿ä¹¾æ·¨ï¼‰
misclassified_dir = "misclassified"
if os.path.exists(misclassified_dir):
    print("ğŸ§¹ æ¸…ç†èˆŠçš„ misclassified è³‡æ–™å¤¾...")
    shutil.rmtree(misclassified_dir)
os.makedirs(misclassified_dir, exist_ok=True)

def ensure_subdirs(base_path):
    """ç¢ºä¿ base_path ä¸‹æœ‰ cat/ dog/ å…©å€‹å­è³‡æ–™å¤¾"""
    for cls in ["cat", "dog"]:
        os.makedirs(os.path.join(base_path, cls), exist_ok=True)

def evaluate_and_save(dataset_name, dataset_path):
    """é æ¸¬è³‡æ–™é›†ï¼Œä¸¦å°‡éŒ¯èª¤åœ–ç‰‡è¤‡è£½åˆ° misclassified/{dataset_name}/"""
    print(f"\nğŸ” é–‹å§‹æª¢æŸ¥ {dataset_name} è³‡æ–™é›†...")

    gen = datagen.flow_from_directory(
        dataset_path,
        target_size=img_size,
        batch_size=1,   # ä¸€æ¬¡ä¸€å¼µï¼Œæ–¹ä¾¿å°æ‡‰
        class_mode='binary',
        shuffle=False
    )

    # é æ¸¬
    pred_probs = model.predict(gen, verbose=1)
    pred_labels = (pred_probs > 0.5).astype(int).flatten()
    true_labels = gen.classes
    file_paths = gen.filepaths

    # å»ºç«‹ dataset å°æ‡‰çš„ misclassified å­è³‡æ–™å¤¾
    dataset_mis_dir = os.path.join(misclassified_dir, dataset_name)
    os.makedirs(dataset_mis_dir, exist_ok=True)
    ensure_subdirs(dataset_mis_dir)

    # çµ±è¨ˆéŒ¯èª¤
    misclassified_count = 0
    for idx, (true_label, pred_label) in enumerate(zip(true_labels, pred_labels)):
        if true_label != pred_label:
            src_path = file_paths[idx]
            filename = os.path.basename(src_path)

            # æ ¹æ“šçœŸå¯¦æ¨™ç±¤åˆ†é¡åˆ° cat/dog
            if true_label == 0:  # çœŸå¯¦æ˜¯ cat
                dst_path = os.path.join(dataset_mis_dir, "cat", f"wrong_pred_{filename}")
            else:  # çœŸå¯¦æ˜¯ dog
                dst_path = os.path.join(dataset_mis_dir, "dog", f"wrong_pred_{filename}")

            # è¤‡è£½æª”æ¡ˆ
            shutil.copy(src_path, dst_path)
            misclassified_count += 1

    # è¨ˆç®—æº–ç¢ºç‡
    total_images = len(true_labels)
    accuracy = (1 - misclassified_count / total_images) * 100
    print(f"âœ… {dataset_name} é›†ç¸½å…± {total_images} å¼µ")
    print(f"âŒ éŒ¯èª¤ {misclassified_count} å¼µï¼Œæ­£ç¢ºç‡ {accuracy:.2f}%")

    return total_images, misclassified_count, accuracy

# 6ï¸âƒ£ åŸ·è¡Œ train èˆ‡ val çš„éŒ¯èª¤æª¢æŸ¥
results = {}
for name, path in datasets.items():
    total, wrong, acc = evaluate_and_save(name, path)
    results[name] = {"total": total, "wrong": wrong, "accuracy": acc}

# 7ï¸âƒ£ æœ€å¾Œè¼¸å‡ºç¸½çµ
print("\nğŸ“Š æœ€çµ‚çµæœç¸½çµï¼š")
for ds, info in results.items():
    print(f"â¡ {ds}: {info['accuracy']:.2f}% (éŒ¯èª¤ {info['wrong']}/{info['total']})")

print("\nâœ… æ‰€æœ‰éŒ¯èª¤åœ–ç‰‡å·²è¤‡è£½åˆ° misclassified/ è³‡æ–™å¤¾å…§")
